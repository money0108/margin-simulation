# =============================================================================
# é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å¹³å° - Streamlit ä¸»ç¨‹å¼
# ç‰ˆæœ¬ï¼šv1.0.0
# åŠŸèƒ½ï¼šä¸Šå‚³éƒ¨ä½ã€é¸æ“‡å»ºå€‰æ—¥æœŸã€å›æ”¾é€æ—¥çµæœã€è¼¸å‡ºç¨½æ ¸åŒ…
# =============================================================================

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import zipfile
import os

# è¼‰å…¥æ ¸å¿ƒæ¨¡çµ„
from core.data_loader import DataLoader
from core.engine import BacktestEngine, BacktestResults
from core.reporting import ReportGenerator, verify
from core.data_loader import DataLoader as _DL  # for compute_position_diffs

# =============================================================================
# é é¢è¨­å®š
# =============================================================================
st.set_page_config(
    page_title="é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# æ¨£å¼è¨­å®š
# =============================================================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .warning-card {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #ffc107;
    }
    .error-card {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #dc3545;
    }
    .success-card {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)


# =============================================================================
# åˆå§‹åŒ– Session State
# =============================================================================
if 'data_loader' not in st.session_state:
    st.session_state.data_loader = None
if 'backtest_results' not in st.session_state:
    st.session_state.backtest_results = None
if 'positions' not in st.session_state:
    st.session_state.positions = None
if 'position_schedule' not in st.session_state:
    st.session_state.position_schedule = None
if 'position_diffs' not in st.session_state:
    st.session_state.position_diffs = None
if 'multi_mode' not in st.session_state:
    st.session_state.multi_mode = False


# =============================================================================
# è¼”åŠ©å‡½å¼
# =============================================================================
@st.cache_resource
def init_data_loader():
    """åˆå§‹åŒ–è³‡æ–™è¼‰å…¥å™¨ï¼ˆå¿«å–ï¼‰"""
    try:
        loader = DataLoader()
        return loader, None
    except Exception as e:
        return None, str(e)


@st.cache_data
def get_trading_dates(_loader):
    """å–å¾—äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆå¿«å–ï¼‰"""
    try:
        prices = _loader.load_prices()
        dates = sorted(prices['date'].unique())
        return dates, None
    except Exception as e:
        return [], str(e)


def estimate_mv(positions_df: pd.DataFrame, prices_df: pd.DataFrame,
                as_of_date=None) -> dict:
    """
    ç”¨éƒ¨ä½ + è‚¡åƒ¹ä¼°ç®—å¤šç©ºå¸‚å€¼æ‘˜è¦

    Returns:
        dict with long_mv, short_mv, long_count, short_count, total_count
    """
    if prices_df is None or len(prices_df) == 0:
        return None

    # å–æœ€è¿‘å¯ç”¨æ—¥æœŸçš„åƒ¹æ ¼
    if as_of_date is not None:
        mask = prices_df['date'] <= pd.Timestamp(as_of_date)
        if mask.any():
            latest_date = prices_df.loc[mask, 'date'].max()
        else:
            latest_date = prices_df['date'].min()
    else:
        latest_date = prices_df['date'].max()

    price_map = prices_df[prices_df['date'] == latest_date].set_index('code')['close'].to_dict()

    long_mv = 0.0
    short_mv = 0.0
    long_count = 0
    short_count = 0
    missing = []

    for _, row in positions_df.iterrows():
        code = str(row['code']).strip()
        qty = float(row['qty'])
        price = price_map.get(code)
        if price is None:
            missing.append(code)
            continue
        mv = qty * price
        if row['side'] == 'LONG':
            long_mv += mv
            long_count += 1
        else:
            short_mv += mv
            short_count += 1

    return {
        'long_mv': long_mv, 'short_mv': short_mv,
        'long_count': long_count, 'short_count': short_count,
        'total_count': long_count + short_count,
        'missing': missing,
    }


def load_prices_from_upload(uploaded_file):
    """å¾ä¸Šå‚³çš„æ–‡ä»¶è¼‰å…¥è‚¡åƒ¹æ•¸æ“š"""
    try:
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        col_map = {'æ—¥æœŸ': 'date', 'è‚¡ç¥¨ä»£è™Ÿ': 'code', 'æ”¶ç›¤åƒ¹': 'close'}
        for std_name, orig_name in col_map.items():
            if orig_name in df.columns:
                df = df.rename(columns={orig_name: std_name})

        # æ—¥æœŸæ ¼å¼è½‰æ›
        df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d', errors='coerce')
        df['code'] = df['code'].astype(str).str.strip()
        df['close'] = pd.to_numeric(df['close'], errors='coerce')
        df = df.dropna(subset=['date', 'code', 'close'])
        df = df.sort_values(['code', 'date']).reset_index(drop=True)
        return df, None
    except Exception as e:
        return None, str(e)


def create_timeseries_chart(df: pd.DataFrame) -> go.Figure:
    """å»ºç«‹ IM/Equity/MM æ™‚åºåœ–"""
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        subplot_titles=('IM/MM/Equity æ™‚åº', 'æ§“æ¡¿å€æ•¸æ™‚åº'),
        row_heights=[0.6, 0.4]
    )

    # ä¸Šåœ–ï¼šIM, MM, Equity
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['IM_today'], name='IM_today',
                  line=dict(color='#1f77b4', width=2)),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['MM_today'], name='MM_today (70%)',
                  line=dict(color='#ff7f0e', width=2, dash='dash')),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['Equity'], name='Equity',
                  line=dict(color='#2ca02c', width=2)),
        row=1, col=1
    )

    # æ¨™è¨˜è¿½ç¹³æ—¥
    margin_call_df = df[df['margin_call_flag'] == 1]
    if len(margin_call_df) > 0:
        fig.add_trace(
            go.Scatter(x=margin_call_df['date'], y=margin_call_df['Equity'],
                      mode='markers', name='è¿½ç¹³è§¸ç™¼',
                      marker=dict(color='red', size=12, symbol='x')),
            row=1, col=1
        )

    # ä¸‹åœ–ï¼šæ§“æ¡¿
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['Gross_Lev'], name='Grossæ§“æ¡¿(æœ‰æŠ˜æ¸›)',
                  line=dict(color='#9467bd', width=2)),
        row=2, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['date'], y=df['Raw_Lev'], name='ç„¡æŠ˜æ¸›æ§“æ¡¿',
                  line=dict(color='#8c564b', width=2, dash='dot')),
        row=2, col=1
    )

    # éƒ¨ä½è®Šå‹•æ—¥æ¨™è¨˜ç´«è‰²è™›ç·š
    if 'position_change_flag' in df.columns:
        change_dates = df[df['position_change_flag'] == 1]['date']
        for cd in change_dates:
            cd_str = cd.isoformat() if hasattr(cd, 'isoformat') else str(cd)
            for row_idx in [1, 2]:
                fig.add_shape(
                    type="line", x0=cd_str, x1=cd_str, y0=0, y1=1,
                    yref="paper" if row_idx == 1 else f"y{row_idx} domain",
                    line=dict(dash="dash", color="purple", width=1.5),
                    row=row_idx, col=1
                )
            fig.add_annotation(
                x=cd_str, y=1, yref="paper",
                text="åŠ æ¸›å€‰", showarrow=False,
                font=dict(color="purple", size=10),
                xanchor="left", yanchor="bottom"
            )

    fig.update_layout(
        height=600,
        showlegend=True,
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
    )

    fig.update_yaxes(title_text='é‡‘é¡ (TWD)', row=1, col=1)
    fig.update_yaxes(title_text='æ§“æ¡¿å€æ•¸', row=2, col=1)
    fig.update_xaxes(title_text='æ—¥æœŸ', row=2, col=1)

    return fig


def create_reduction_chart(df: pd.DataFrame) -> go.Figure:
    """å»ºç«‹æŠ˜æ¸›ä¾†æºå †ç–Šåœ–"""
    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=df['date'],
        y=df['reduction_etf_100'],
        name='ETF 100% æŠ˜æ¸›',
        marker_color='#1f77b4'
    ))

    fig.add_trace(go.Bar(
        x=df['date'],
        y=df['reduction_same_bucket'],
        name='åŒæ¡¶æŠ˜æ¸›',
        marker_color='#ff7f0e'
    ))

    fig.add_trace(go.Bar(
        x=df['date'],
        y=df['reduction_cross_bucket'],
        name='è·¨æ¡¶æŠ˜æ¸›',
        marker_color='#2ca02c'
    ))

    fig.update_layout(
        barmode='stack',
        title='æŠ˜æ¸›ä¾†æºåˆ†è§£',
        xaxis_title='æ—¥æœŸ',
        yaxis_title='æŠ˜æ¸›é‡‘é¡ (TWD)',
        height=400
    )

    return fig


def create_mv_chart(df: pd.DataFrame) -> go.Figure:
    """å»ºç«‹ MV æ™‚åºåœ–"""
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=df['date'],
        y=df['Long_MV'],
        name='Long MV',
        fill='tozeroy',
        line=dict(color='#2ca02c')
    ))

    fig.add_trace(go.Scatter(
        x=df['date'],
        y=-df['Short_MV'],  # è² å€¼é¡¯ç¤ºåœ¨ä¸‹æ–¹
        name='Short MV',
        fill='tozeroy',
        line=dict(color='#d62728')
    ))

    fig.update_layout(
        title='å¤šç©ºå¸‚å€¼æ™‚åº',
        xaxis_title='æ—¥æœŸ',
        yaxis_title='å¸‚å€¼ (TWD)',
        height=400
    )

    return fig


def _generate_hedge_sections(results: BacktestResults) -> str:
    """ç”Ÿæˆå¤šç©ºé…å°èˆ‡æ¸›æ”¶æ˜ç´°çš„ HTML å€å¡Šï¼ˆå»ºå€‰æ—¥ + è¿½ç¹³æ—¥ï¼‰"""
    if not results.daily_results:
        return '<p>ç„¡é…å°æ˜ç´°</p>'

    sections = []

    # æ”¶é›†éœ€è¦é¡¯ç¤ºçš„æ—¥æœŸï¼šå»ºå€‰æ—¥ + æ‰€æœ‰è¿½ç¹³æ—¥
    display_dates = []

    # å»ºå€‰æ—¥
    first_result = results.daily_results[0]
    display_dates.append(('å»ºå€‰æ—¥', first_result))

    # è¿½ç¹³æ—¥
    for dr in results.daily_results[1:]:
        if dr.margin_result.margin_call:
            date_str = dr.date.strftime('%Y-%m-%d')
            display_dates.append((f'è¿½ç¹³æ—¥ {date_str}', dr))

    for label, dr in display_dates:
        hedge_df = dr.margin_result.hedge_pairing_df
        mr = dr.margin_result
        date_str = dr.date.strftime('%Y-%m-%d')

        section_html = f'''
        <div style="margin-bottom: 30px; padding: 15px; background: #f9f9f9; border-radius: 8px;">
            <h3 style="color: #1f77b4; margin-top: 0;">{label} - {date_str}</h3>
        '''

        if len(hedge_df) > 0:
            # æ‘˜è¦çµ±è¨ˆ
            paired_count = len(hedge_df[hedge_df['é…å°MV'] > 0])
            total_hedged = hedge_df['é…å°MV'].sum()
            total_reduction = hedge_df['æ¸›æ”¶IM'].sum()

            section_html += f'''
            <div class="summary-grid" style="margin-bottom: 15px;">
                <div class="metric-card" style="display: inline-block; margin-right: 15px; min-width: 120px;">
                    <div class="metric-value">{paired_count}</div>
                    <div class="metric-label">é…å°æ¨™çš„æ•¸</div>
                </div>
                <div class="metric-card" style="display: inline-block; margin-right: 15px; min-width: 120px;">
                    <div class="metric-value">{total_hedged:,.0f}</div>
                    <div class="metric-label">ç¸½é…å°MV</div>
                </div>
                <div class="metric-card" style="display: inline-block; margin-right: 15px; min-width: 120px;">
                    <div class="metric-value">{total_reduction:,.0f}</div>
                    <div class="metric-label">ç¸½æ¸›æ”¶IM</div>
                </div>
                <div class="metric-card" style="display: inline-block; margin-right: 15px; min-width: 120px;">
                    <div class="metric-value">{mr.im_today:,.0f}</div>
                    <div class="metric-label">ç•¶æ—¥IM</div>
                </div>
            </div>
            '''

            # æ ¼å¼åŒ–é…å°æ˜ç´°è¡¨
            hedge_display = hedge_df.copy()
            for col in hedge_display.columns:
                if col not in ['ä»£è™Ÿ', 'æ–¹å‘', 'ç”¢æ¥­æ¡¶', 'é…å°é¡å‹', 'æ¸›æ”¶ç‡']:
                    hedge_display[col] = hedge_display[col].apply(
                        lambda x: f'{x:,.0f}' if pd.notna(x) and isinstance(x, (int, float)) else x
                    )

            section_html += f'''
            <div style="max-height: 300px; overflow-y: auto;">
                {hedge_display.to_html(index=False, classes='data-table', escape=False)}
            </div>
            '''

            # æŠ˜æ¸›ä¾†æºåˆ†è§£
            section_html += f'''
            <p style="margin-top: 15px;"><strong>æŠ˜æ¸›ä¾†æºåˆ†è§£ï¼š</strong></p>
            <div style="display: flex; gap: 20px;">
                <div>ETFå®Œå…¨å°æ²–(100%): <strong>{mr.reduction_etf_100:,.0f}</strong></div>
                <div>åŒæ¡¶å°æ²–: <strong>{mr.reduction_same_bucket:,.0f}</strong></div>
                <div>è·¨æ¡¶å°æ²–: <strong>{mr.reduction_cross_bucket:,.0f}</strong></div>
            </div>
            '''
        else:
            section_html += '<p style="color: #666;">ç„¡å¤šç©ºé…å°</p>'

        section_html += '</div>'
        sections.append(section_html)

    return '\n'.join(sections)


def _generate_position_change_html(results: BacktestResults) -> str:
    """ç”Ÿæˆéƒ¨ä½è®Šå‹•è³‡è¨Šçš„ HTML å€å¡Š"""
    if not results.position_change_events:
        return ''

    html = '<h2>ğŸ“¦ éƒ¨ä½è®Šå‹•ç´€éŒ„</h2>'

    # æ™‚é–“ç·š
    html += '<div style="margin-bottom:20px;">'
    html += '<table><tr><th>æ—¥æœŸ</th><th>æ–° IM</th><th>æ–° MM</th><th>è®Šå‹•æ™‚æ¬Šç›Š</th><th>å¤šæ–¹ MV</th><th>ç©ºæ–¹ MV</th><th>å¯¦ç¾æç›Š</th><th>å‡ºé‡‘</th></tr>'
    for evt in results.position_change_events:
        html += f"<tr><td>{evt['date'].strftime('%Y-%m-%d')}</td>"
        html += f"<td>{evt['new_im']:,.0f}</td>"
        html += f"<td>{evt['new_mm']:,.0f}</td>"
        html += f"<td>{evt['equity_at_change']:,.0f}</td>"
        html += f"<td>{evt['long_mv']:,.0f}</td>"
        html += f"<td>{evt['short_mv']:,.0f}</td>"
        html += f"<td>{evt.get('realized_pnl', 0):+,.0f}</td>"
        html += f"<td>{evt.get('withdrawal', 0):,.0f}</td></tr>"
    html += '</table></div>'

    return html


def create_html_report(results: BacktestResults, positions: pd.DataFrame) -> str:
    """å»ºç«‹å®Œæ•´ HTML å ±å‘Šï¼ˆå¯ç¨ç«‹é–‹å•Ÿï¼‰"""
    ts = results.timeseries_df

    # å»ºç«‹åœ–è¡¨
    fig1 = create_timeseries_chart(ts)
    fig2 = create_mv_chart(ts)
    fig3 = create_reduction_chart(ts)

    chart1_html = fig1.to_html(full_html=False, include_plotlyjs='cdn')
    chart2_html = fig2.to_html(full_html=False, include_plotlyjs=False)
    chart3_html = fig3.to_html(full_html=False, include_plotlyjs=False)

    # æ‘˜è¦æ•¸æ“š
    first_day = ts.iloc[0]
    last_day = ts.iloc[-1]

    # æ¬Šç›Šæç›Šè¡¨
    equity_cols = ['date', 'Long_MV', 'Short_MV',
                  'Daily_PnL_Long', 'Daily_PnL_Short', 'Daily_PnL',
                  'Cum_PnL_Long', 'Cum_PnL_Short', 'Cumulative_PnL',
                  'Equity_Before', 'MM_At_Call', 'IM_today',
                  'margin_call_flag', 'Required_Deposit', 'Equity', 'MM_today']
    equity_df = ts[[c for c in equity_cols if c in ts.columns]].copy()
    equity_df['date'] = equity_df['date'].dt.strftime('%Y-%m-%d')

    # æ ¼å¼åŒ–æ•¸å­—æ¬„ä½
    for col in equity_df.columns:
        if col != 'date' and col != 'margin_call_flag':
            equity_df[col] = equity_df[col].apply(lambda x: f'{x:,.0f}' if pd.notna(x) else '')

    equity_df.columns = ['æ—¥æœŸ', 'å¤šæ–¹MV', 'ç©ºæ–¹MV', 'å¤šæ–¹æ—¥æç›Š', 'ç©ºæ–¹æ—¥æç›Š', 'åˆè¨ˆæ—¥æç›Š',
                        'å¤šæ–¹ç´¯è¨ˆ', 'ç©ºæ–¹ç´¯è¨ˆ', 'åˆè¨ˆç´¯è¨ˆ', 'æ¬Šç›Š(åˆ¤å®š)', 'MM(åˆ¤å®š)', 'IM',
                        'è¿½ç¹³', 'è¿½ç¹³é‡‘é¡', 'æ¬Šç›Š(è£œå¾Œ)', 'MM(è£œå¾Œ)'][:len(equity_df.columns)]

    # ä¿è­‰é‡‘æ˜ç´°è¡¨
    margin_cols = ['date', 'Base_IM_long', 'Base_IM_short', 'IM_big', 'IM_small_before',
                  'reduction_etf_100', 'reduction_same_bucket', 'reduction_cross_bucket',
                  'total_reduction', 'IM_small_after', 'IM_today', 'Gross_Lev', 'Raw_Lev']
    margin_df = ts[[c for c in margin_cols if c in ts.columns]].copy()
    margin_df['date'] = margin_df['date'].dt.strftime('%Y-%m-%d')

    # æ ¼å¼åŒ–æ•¸å­—æ¬„ä½
    for col in margin_df.columns:
        if col == 'date':
            continue
        elif col in ['Gross_Lev', 'Raw_Lev']:
            margin_df[col] = margin_df[col].apply(lambda x: f'{x:.2f}' if pd.notna(x) else '')
        else:
            margin_df[col] = margin_df[col].apply(lambda x: f'{x:,.0f}' if pd.notna(x) else '')

    margin_df.columns = ['æ—¥æœŸ', 'å¤šæ–¹Base_IM', 'ç©ºæ–¹Base_IM', 'IMå¤§é‚Š', 'IMå°é‚Š(æŠ˜å‰)',
                        'ETFæŠ˜æ¸›', 'åŒæ¡¶æŠ˜æ¸›', 'è·¨æ¡¶æŠ˜æ¸›', 'ç¸½æŠ˜æ¸›',
                        'IMå°é‚Š(æŠ˜å¾Œ)', 'IM_today', 'Grossæ§“æ¡¿', 'ç„¡æŠ˜æ¸›æ§“æ¡¿'][:len(margin_df.columns)]

    # èè³‡è²»ç”¨è¡¨
    financing_cols = ['date', 'Long_MV', 'Short_MV', 'IM_today',
                     'Long_Financing', 'Short_Financing', 'Financing_Amount',
                     'Daily_Interest', 'Cumulative_Interest',
                     'Daily_Broker_Profit', 'Cumulative_Broker_Profit']
    financing_df = ts[[c for c in financing_cols if c in ts.columns]].copy()
    financing_df['date'] = financing_df['date'].dt.strftime('%Y-%m-%d')

    for col in financing_df.columns:
        if col != 'date':
            financing_df[col] = financing_df[col].apply(lambda x: f'{x:,.0f}' if pd.notna(x) else '')

    financing_df.columns = ['æ—¥æœŸ', 'å¤šæ–¹MV', 'ç©ºæ–¹MV', 'IM',
                           'å¤šæ–¹èè³‡', 'ç©ºæ–¹èè³‡', 'ç¸½èè³‡',
                           'ç•¶æ—¥åˆ©æ¯', 'ç´¯è¨ˆåˆ©æ¯', 'ç•¶æ—¥åˆ¸å•†æ”¶ç›Š', 'ç´¯è¨ˆåˆ¸å•†æ”¶ç›Š'][:len(financing_df.columns)]

    # å¤šç©ºé…å°æ˜ç´°
    hedge_df = results.daily_results[0].margin_result.hedge_pairing_df if results.daily_results else pd.DataFrame()

    # ç”Ÿæˆ HTML
    html = f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å ±å‘Š</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Microsoft JhengHei", sans-serif;
            margin: 0; padding: 20px; background: #f5f5f5;
        }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        h1 {{ color: #1f77b4; border-bottom: 3px solid #1f77b4; padding-bottom: 10px; }}
        h2 {{ color: #333; margin-top: 30px; border-left: 4px solid #1f77b4; padding-left: 10px; }}
        .summary-grid {{
            display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px; margin: 20px 0;
        }}
        .metric-card {{
            background: white; padding: 20px; border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); text-align: center;
        }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #1f77b4; }}
        .metric-label {{ font-size: 14px; color: #666; margin-top: 5px; }}
        .chart-container {{ background: white; padding: 20px; border-radius: 8px; margin: 20px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        table {{
            width: 100%; border-collapse: collapse; background: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin: 20px 0;
        }}
        th, td {{ padding: 10px; text-align: right; border: 1px solid #ddd; font-size: 13px; }}
        th {{ background: #1f77b4; color: white; position: sticky; top: 0; }}
        tr:nth-child(even) {{ background: #f9f9f9; }}
        tr:hover {{ background: #e8f4fc; }}
        td:first-child, th:first-child {{ text-align: left; }}
        .table-wrapper {{ max-height: 400px; overflow-y: auto; margin: 20px 0; }}
        .warning {{ background: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin: 10px 0; }}
        .info {{ background: #d1ecf1; border-left: 4px solid #17a2b8; padding: 15px; margin: 10px 0; }}
        .footer {{ text-align: center; color: #666; margin-top: 40px; padding: 20px; border-top: 1px solid #ddd; }}
        .negative {{ color: #dc3545; }}
        .positive {{ color: #28a745; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å ±å‘Š</h1>
        <p style="color:#666;">ç”¢å‡ºæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

        <h2>ğŸ“‹ æ¨¡æ“¬æ‘˜è¦</h2>
        <div class="summary-grid">
            <div class="metric-card">
                <div class="metric-value">{first_day['date'].strftime('%Y-%m-%d') if hasattr(first_day['date'], 'strftime') else first_day['date']}</div>
                <div class="metric-label">å»ºå€‰æ—¥æœŸ</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['date'].strftime('%Y-%m-%d') if hasattr(last_day['date'], 'strftime') else last_day['date']}</div>
                <div class="metric-label">çµæŸæ—¥æœŸ</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{len(ts)}</div>
                <div class="metric-label">äº¤æ˜“æ—¥æ•¸</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{first_day['IM_today']:,.0f}</div>
                <div class="metric-label">å»ºå€‰æ—¥ IM</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['IM_today']:,.0f}</div>
                <div class="metric-label">æœ€æ–° IM</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['Equity']:,.0f}</div>
                <div class="metric-label">æœ€æ–°æ¬Šç›Š</div>
            </div>
            <div class="metric-card">
                <div class="metric-value {'negative' if last_day['Cumulative_PnL'] < 0 else 'positive'}">{last_day['Cumulative_PnL']:+,.0f}</div>
                <div class="metric-label">ç´¯è¨ˆæç›Š</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{int(ts['margin_call_flag'].sum())}</div>
                <div class="metric-label">è¿½ç¹³æ¬¡æ•¸</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['Financing_Amount']:,.0f}</div>
                <div class="metric-label">èè³‡é‡‘é¡</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['Cumulative_Interest']:,.0f}</div>
                <div class="metric-label">ç´¯è¨ˆåˆ©æ¯æ”¯å‡º</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{last_day['Cumulative_Broker_Profit']:,.0f}</div>
                <div class="metric-label">åˆ¸å•†ç´¯è¨ˆæ”¶ç›Š</div>
            </div>
        </div>

        <h2>ğŸ“ˆ IM / MM / æ¬Šç›Šèµ°å‹¢</h2>
        <div class="chart-container">{chart1_html}</div>

        <h2>ğŸ“Š å¤šç©ºå¸‚å€¼èµ°å‹¢</h2>
        <div class="chart-container">{chart2_html}</div>

        <h2>ğŸ“‰ æŠ˜æ¸›ä¾†æºåˆ†è§£</h2>
        <div class="chart-container">{chart3_html}</div>

        <h2>ğŸ’° æ¬Šç›Šèˆ‡æç›Šè¿½è¹¤</h2>
        <div class="table-wrapper">
            {equity_df.to_html(index=False, classes='data-table', escape=False)}
        </div>

        <h2>ğŸ§® ä¿è­‰é‡‘è¨ˆç®—æ˜ç´°</h2>
        <div class="table-wrapper">
            {margin_df.to_html(index=False, classes='data-table', escape=False)}
        </div>

        <h2>ğŸ’³ èè³‡è²»ç”¨æ˜ç´°</h2>
        <p style="color:#666;font-size:13px;">å¤šæ–¹èè³‡ = å¤šæ–¹MV - IMï½œç©ºæ–¹èè³‡ = ç©ºæ–¹MVï¼ˆå€Ÿåˆ¸è³£å‡ºä¸ç¹³ä¿è­‰é‡‘ï¼‰ï½œå®¢æˆ¶åˆ©ç‡ 3%ï½œåˆ¸å•†æ”¶ç›Š = å¤šæ–¹èè³‡Ã—1.2% + ç©ºæ–¹èè³‡Ã—3%ï½œåˆ©æ¯æŒ‰æ—¥æ›†æ—¥è¨ˆç®—</p>
        <div class="table-wrapper">
            {financing_df.to_html(index=False, classes='data-table', escape=False)}
        </div>

        <h2>ğŸ”„ å¤šç©ºé…å°èˆ‡æ¸›æ”¶æ˜ç´°</h2>
        {_generate_hedge_sections(results)}

        <h2>ğŸ“ å‡è¨­èˆ‡èªªæ˜</h2>
        <div class="info">
            <ul>
                {''.join(f'<li>{a}</li>' for a in results.assumptions)}
            </ul>
        </div>

        {f'<div class="warning"><strong>âš ï¸ è¿½ç¹³äº‹ä»¶ï¼š</strong>å…± {len(results.margin_call_events)} æ¬¡è¿½ç¹³</div>' if results.margin_call_events else ''}

        {_generate_position_change_html(results)}

        <div class="footer">
            <p>é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å¹³å° v1.0</p>
            <p>æ­¤å ±å‘Šç”±ç³»çµ±è‡ªå‹•ç”¢ç”Ÿï¼Œåƒ…ä¾›åƒè€ƒ</p>
        </div>
    </div>
</body>
</html>'''

    return html


def create_full_report_excel(results: BacktestResults, positions: pd.DataFrame) -> bytes:
    """å»ºç«‹å®Œæ•´å ±å‘Š Excelï¼ˆå¤šå·¥ä½œè¡¨ï¼‰"""
    output = io.BytesIO()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # 1. æ‘˜è¦
        ts = results.timeseries_df
        if len(ts) > 0:
            first_day = ts.iloc[0]
            last_day = ts.iloc[-1]
            summary_data = {
                'é …ç›®': [
                    'æ¨¡æ“¬æœŸé–“', 'äº¤æ˜“æ—¥æ•¸', 'å»ºå€‰æ—¥IM', 'æœ€æ–°IM',
                    'å»ºå€‰æ—¥MM', 'æœ€æ–°MM', 'æœ€æ–°æ¬Šç›Š', 'ç´¯è¨ˆæç›Š',
                    'è¿½ç¹³æ¬¡æ•¸', 'å¹³å‡Grossæ§“æ¡¿', 'å¹³å‡ç„¡æŠ˜æ¸›æ§“æ¡¿'
                ],
                'æ•¸å€¼': [
                    f"{first_day['date'].strftime('%Y-%m-%d') if hasattr(first_day['date'], 'strftime') else first_day['date']} ~ {last_day['date'].strftime('%Y-%m-%d') if hasattr(last_day['date'], 'strftime') else last_day['date']}",
                    len(ts),
                    f"{first_day['IM_today']:,.0f}",
                    f"{last_day['IM_today']:,.0f}",
                    f"{first_day['MM_today']:,.0f}",
                    f"{last_day['MM_today']:,.0f}",
                    f"{last_day['Equity']:,.0f}",
                    f"{last_day['Cumulative_PnL']:,.0f}",
                    int(ts['margin_call_flag'].sum()),
                    f"{ts['Gross_Lev'].mean():.2f}x",
                    f"{ts['Raw_Lev'].mean():.2f}x"
                ]
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='æ‘˜è¦', index=False)

        # 2. æ¬Šç›Šèˆ‡æç›Šè¿½è¹¤
        if len(ts) > 0:
            equity_cols = ['date', 'Long_MV', 'Short_MV',
                          'Daily_PnL_Long', 'Daily_PnL_Short', 'Daily_PnL',
                          'Cum_PnL_Long', 'Cum_PnL_Short', 'Cumulative_PnL',
                          'Equity', 'MM_today', 'IM_today', 'margin_call_flag', 'Required_Deposit']
            equity_df = ts[[c for c in equity_cols if c in ts.columns]].copy()
            equity_df.columns = ['æ—¥æœŸ', 'å¤šæ–¹MV', 'ç©ºæ–¹MV',
                                'å¤šæ–¹æ—¥æç›Š', 'ç©ºæ–¹æ—¥æç›Š', 'åˆè¨ˆæ—¥æç›Š',
                                'å¤šæ–¹ç´¯è¨ˆ', 'ç©ºæ–¹ç´¯è¨ˆ', 'åˆè¨ˆç´¯è¨ˆ',
                                'æ¬Šç›Š', 'MM', 'IM', 'è¿½ç¹³', 'è¿½ç¹³é‡‘é¡'][:len(equity_df.columns)]
            equity_df.to_excel(writer, sheet_name='æ¬Šç›Šæç›Šè¿½è¹¤', index=False)

        # 3. ä¿è­‰é‡‘è¨ˆç®—æ˜ç´°
        if len(ts) > 0:
            margin_cols = ['date', 'Base_IM_long', 'Base_IM_short', 'IM_big', 'IM_small_before',
                          'reduction_etf_100', 'reduction_same_bucket', 'reduction_cross_bucket',
                          'total_reduction', 'IM_small_after', 'IM_today', 'Gross_Lev', 'Raw_Lev']
            margin_df = ts[[c for c in margin_cols if c in ts.columns]].copy()
            margin_df.columns = ['æ—¥æœŸ', 'å¤šæ–¹Base_IM', 'ç©ºæ–¹Base_IM', 'IMå¤§é‚Š', 'IMå°é‚Š(æŠ˜å‰)',
                                'ETFæŠ˜æ¸›', 'åŒæ¡¶æŠ˜æ¸›', 'è·¨æ¡¶æŠ˜æ¸›', 'ç¸½æŠ˜æ¸›',
                                'IMå°é‚Š(æŠ˜å¾Œ)', 'IM_today', 'Grossæ§“æ¡¿', 'ç„¡æŠ˜æ¸›æ§“æ¡¿'][:len(margin_df.columns)]
            margin_df.to_excel(writer, sheet_name='ä¿è­‰é‡‘è¨ˆç®—æ˜ç´°', index=False)

        # 4. å»ºå€‰æ—¥å¤šç©ºé…å°
        if results.daily_results:
            hedge_df = results.daily_results[0].margin_result.hedge_pairing_df
            if len(hedge_df) > 0:
                hedge_df.to_excel(writer, sheet_name='å¤šç©ºé…å°æ˜ç´°', index=False)

        # 5. éƒ¨ä½æ¸…å–®
        positions.to_excel(writer, sheet_name='éƒ¨ä½æ¸…å–®', index=False)

        # 6. è¿½ç¹³äº‹ä»¶
        if results.margin_call_events:
            events_df = pd.DataFrame(results.margin_call_events)
            events_df.to_excel(writer, sheet_name='è¿½ç¹³äº‹ä»¶', index=False)

        # 7. å‡è¨­èªªæ˜
        assumptions_df = pd.DataFrame({
            'å‡è¨­èªªæ˜': results.assumptions
        })
        assumptions_df.to_excel(writer, sheet_name='å‡è¨­èªªæ˜', index=False)

        # 8. éƒ¨ä½è®Šå‹•äº‹ä»¶
        if results.position_change_events:
            change_df = pd.DataFrame(results.position_change_events)
            change_df.to_excel(writer, sheet_name='éƒ¨ä½è®Šå‹•äº‹ä»¶', index=False)

        # 9. ç¼ºç¢¼æ¸…å–®
        if results.missing_codes:
            missing_df = pd.DataFrame({
                'ç¼ºç¢¼ä»£è™Ÿ': results.missing_codes
            })
            missing_df.to_excel(writer, sheet_name='ç¼ºç¢¼æ¸…å–®', index=False)

    output.seek(0)
    return output.getvalue()


def create_audit_zip(results: BacktestResults, positions: pd.DataFrame) -> bytes:
    """å»ºç«‹ç¨½æ ¸åŒ… ZIP"""
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        # æœ€çµ‚æ™‚åº
        csv_buffer = io.StringIO()
        results.timeseries_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        zf.writestr('final_timeseries.csv', csv_buffer.getvalue().encode('utf-8-sig'))

        # éƒ¨ä½å¿«ç…§
        csv_buffer = io.StringIO()
        positions.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        zf.writestr('inputs_snapshot/positions.csv', csv_buffer.getvalue().encode('utf-8-sig'))

        # è¿½ç¹³äº‹ä»¶
        if results.margin_call_events:
            csv_buffer = io.StringIO()
            pd.DataFrame(results.margin_call_events).to_csv(csv_buffer, index=False)
            zf.writestr('margin_call_events.csv', csv_buffer.getvalue().encode('utf-8-sig'))

        # å‡è¨­èªªæ˜
        assumptions_content = "# å‡è¨­èˆ‡ä¿å®ˆå£å¾‘èªªæ˜\n\n"
        for assumption in results.assumptions:
            assumptions_content += f"- {assumption}\n"
        if results.missing_codes:
            assumptions_content += f"\n## ç¼ºç¢¼æ¸…å–®ï¼ˆå…± {len(results.missing_codes)} æª”ï¼‰\n"
            for code in results.missing_codes[:50]:
                assumptions_content += f"- {code}\n"
        zf.writestr('assumptions.md', assumptions_content.encode('utf-8'))

        # é©—è­‰çµæœ
        verification = verify(results)
        import json
        zf.writestr('verification.json', json.dumps(verification, ensure_ascii=False, indent=2).encode('utf-8'))

        # éƒ¨ä½è®Šå‹•äº‹ä»¶
        if results.position_change_events:
            change_df = pd.DataFrame(results.position_change_events)
            csv_buffer = io.StringIO()
            change_df.to_csv(csv_buffer, index=False)
            zf.writestr('position_change_events.csv', csv_buffer.getvalue().encode('utf-8-sig'))

        # å¤šæœŸéƒ¨ä½å¿«ç…§
        if results.position_schedule and len(results.position_schedule) > 1:
            for s_idx, (s_date, s_df) in enumerate(results.position_schedule):
                csv_buffer = io.StringIO()
                s_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                zf.writestr(
                    f'inputs_snapshot/positions_{s_date.strftime("%Y%m%d")}.csv',
                    csv_buffer.getvalue().encode('utf-8-sig')
                )

        # é€æ—¥æ˜ç´°ï¼ˆé¦–/ä¸­/æœ«æ—¥ï¼‰
        if results.daily_results:
            n = len(results.daily_results)
            sample_indices = [0, n // 2, n - 1] if n >= 3 else list(range(n))

            for idx in sample_indices:
                dr = results.daily_results[idx]
                date_str = dr.date.strftime('%Y%m%d')
                mr = dr.margin_result

                csv_buffer = io.StringIO()
                mr.summary_df.to_csv(csv_buffer, index=False)
                zf.writestr(f'calc_steps/{date_str}_summary.csv', csv_buffer.getvalue().encode('utf-8-sig'))

                csv_buffer = io.StringIO()
                mr.bucket_hedge_df.to_csv(csv_buffer, index=False)
                zf.writestr(f'calc_steps/{date_str}_bucket_hedge.csv', csv_buffer.getvalue().encode('utf-8-sig'))

                csv_buffer = io.StringIO()
                mr.reduction_breakdown_df.to_csv(csv_buffer, index=False)
                zf.writestr(f'calc_steps/{date_str}_reduction_breakdown.csv', csv_buffer.getvalue().encode('utf-8-sig'))

    zip_buffer.seek(0)
    return zip_buffer.getvalue()


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================
def main():
    # æ¨™é¡Œ
    st.markdown('<p class="main-header">é æœŸå¥‘ç´„ä¿è­‰é‡‘æ¨¡æ“¬å¹³å°</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Forward Contract Margin Simulation Platform v1.0</p>', unsafe_allow_html=True)

    # åˆ¶åº¦æ‘˜è¦
    with st.expander("ğŸ“‹ åˆ¶åº¦å£å¾‘ä¸€å¥è©±æ‘˜è¦", expanded=False):
        st.info("""
        **æœ¬åˆ¶åº¦ä»¥å›ºå®šæ§“æ¡¿è¨ˆç®—åˆ†é‚Š Base IMï¼Œä¸¦ä»¥ Base IM åˆ¤å®šå¤§å°é‚Šï¼›**
        å°æ²–æŠ˜æ¸›åƒ…é©ç”¨æ–¼å°é‚Šï¼Œä¾ä¸‰ç”¢æ¥­æ¡¶èˆ‡ 3M åŠ æ¬Šç´¯ç©å ±é…¬ç‡æ±ºå®šæŠ˜æ¸›ç‡ï¼ˆ50% æˆ– 20%ï¼‰ï¼›
        0050/0056 ETF æ¡ look-throughï¼Œæˆä»½è‚¡å®Œå…¨å°æ²–éƒ¨åˆ†å¯ 100% æ¸›æ”¶ï¼›
        ç¶­æŒä¿è­‰é‡‘ç‚ºç•¶æ—¥ IM çš„ 70%ï¼Œè·Œç ´ç¶­æŒä¿è­‰é‡‘æ™‚éœ€è¿½ç¹³å›è£œè‡³ç•¶æ—¥ IMï¼ˆ100%ï¼‰ã€‚
        """)

        st.markdown("""
        **é—œéµè¦å‰‡æ¸…å–®ï¼š**
        | é¡åˆ¥ | æ§“æ¡¿å€æ•¸ |
        |------|---------|
        | ETFï¼ˆæœˆå‡é‡ â‰¥ 10,000 å¼µï¼‰ | 7x |
        | ETFï¼ˆæœˆå‡é‡ < 10,000 å¼µï¼‰ | 5x |
        | è‚¡æœŸæ¨™çš„ï¼ˆè‚¡æœŸæ§“æ¡¿ > 7ï¼‰ | 5x |
        | è‚¡æœŸæ¨™çš„ï¼ˆè‚¡æœŸæ§“æ¡¿ > 6 ä¸” â‰¤ 7ï¼‰ | 4x |
        | è‚¡æœŸæ¨™çš„ï¼ˆè‚¡æœŸæ§“æ¡¿ â‰¤ 6ï¼‰/ å…¶ä»–è‚¡ç¥¨ | 3x |

        | å°æ²–é¡å‹ | æŠ˜æ¸›ç‡ |
        |---------|-------|
        | åŒæ¡¶ï¼ˆ3M å ±é…¬å·® â‰¥ 10%ï¼‰| 50% |
        | åŒæ¡¶ï¼ˆ3M å ±é…¬å·® < 10%ï¼‰| 20% |
        | è·¨æ¡¶ | 20% |
        | ETF å®Œå…¨å°æ²– | 100% |
        """)

    # åˆå§‹åŒ–è³‡æ–™è¼‰å…¥å™¨
    loader, error = init_data_loader()
    if error:
        st.error(f"è³‡æ–™è¼‰å…¥å™¨åˆå§‹åŒ–å¤±æ•—ï¼š{error}")
        st.stop()

    st.session_state.data_loader = loader

    # ==========================================================================
    # å´é‚Šæ¬„è¨­å®š
    # ==========================================================================
    st.sidebar.header("âš™ï¸ åƒæ•¸è¨­å®š")

    # æ•¸æ“šä¾†æºè¨­å®š
    st.sidebar.subheader("0ï¸âƒ£ è‚¡åƒ¹æ•¸æ“š")

    # åˆå§‹åŒ– session state
    if 'prices_df' not in st.session_state:
        st.session_state.prices_df = None
    if 'trading_dates' not in st.session_state:
        st.session_state.trading_dates = []

    # å˜—è©¦å¾é›²ç«¯è¼‰å…¥ï¼Œå¦‚æœå¤±æ•—å‰‡è®“ç”¨æˆ¶ä¸Šå‚³
    trading_dates, price_error = get_trading_dates(loader)

    if price_error:
        st.sidebar.warning("é›²ç«¯æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œè«‹ä¸Šå‚³è‚¡åƒ¹æª”æ¡ˆ")
        price_file = st.sidebar.file_uploader(
            "ä¸Šå‚³è‚¡åƒ¹ CSV",
            type=['csv'],
            help="å¿…é ˆåŒ…å«æ¬„ä½ï¼šæ—¥æœŸã€è‚¡ç¥¨ä»£è™Ÿã€æ”¶ç›¤åƒ¹",
            key="price_upload"
        )
        if price_file is not None:
            prices_df, err = load_prices_from_upload(price_file)
            if err:
                st.sidebar.error(f"è§£æå¤±æ•—ï¼š{err}")
            else:
                st.session_state.prices_df = prices_df
                st.session_state.trading_dates = sorted(prices_df['date'].unique())
                # å°‡è‚¡åƒ¹æ•¸æ“šæ³¨å…¥åˆ° DataLoader
                loader.set_prices_df(prices_df)
                st.sidebar.success(f"å·²è¼‰å…¥ {len(prices_df)} ç­†è‚¡åƒ¹æ•¸æ“š")
                trading_dates = st.session_state.trading_dates
    else:
        st.sidebar.success("âœ“ è‚¡åƒ¹æ•¸æ“šå·²è¼‰å…¥")
        st.session_state.trading_dates = trading_dates

    # å¦‚æœä¹‹å‰å·²ç¶“ä¸Šå‚³éè‚¡åƒ¹ï¼Œç¢ºä¿ DataLoader ä¹Ÿæœ‰é€™ä»½æ•¸æ“š
    if st.session_state.prices_df is not None:
        loader.set_prices_df(st.session_state.prices_df)

    # éƒ¨ä½ä¸Šå‚³ï¼ˆçµ±ä¸€ä»‹é¢ï¼šæ”¯æ´å–®æª”æˆ–å¤šæª”ï¼‰
    st.sidebar.subheader("1ï¸âƒ£ éƒ¨ä½è³‡æ–™")

    uploaded_files = st.sidebar.file_uploader(
        "ä¸Šå‚³éƒ¨ä½ Excelï¼ˆå¯å¤šé¸ï¼‰",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="å–®æª”ï¼åˆå§‹å»ºå€‰ï¼›å¤šæª”ï¼æœ€æ—©æ—¥æœŸç‚ºå»ºå€‰ï¼Œå…¶é¤˜ç‚ºåŠ å€‰/å¹³å€‰ã€‚æª”æ¡ˆç¬¬ä¸€åˆ—è‹¥ç‚ºã€Œæ—¥æœŸ + æ—¥æœŸå€¼ã€æœƒè‡ªå‹•åµæ¸¬ï¼Œå¦å‰‡éœ€æ‰‹å‹•æŒ‡å®šæ—¥æœŸã€‚",
        key="position_upload"
    )

    positions = None

    if uploaded_files and len(uploaded_files) > 0:
        # è§£ææ¯å€‹æª”æ¡ˆï¼Œæª¢æŸ¥æ˜¯å¦æœ‰æ—¥æœŸæ¨™é ­
        parsed_files = []
        needs_date = []

        for idx, uf in enumerate(uploaded_files):
            try:
                raw = pd.read_excel(uf, header=None)
                cell_00 = str(raw.iloc[0, 0]).strip() if len(raw) > 0 else ''

                if cell_00 == 'æ—¥æœŸ':
                    date_val = raw.iloc[0, 1]
                    pos_date = pd.Timestamp(date_val)
                    parsed_files.append({'file': uf, 'name': uf.name, 'date': pos_date, 'has_date': True})
                else:
                    parsed_files.append({'file': uf, 'name': uf.name, 'date': None, 'has_date': False})
                    needs_date.append(idx)
            except Exception as e:
                st.sidebar.error(f"è§£æ {uf.name} å¤±æ•—ï¼š{e}")

        # å°ç¼ºæ—¥æœŸçš„æª”æ¡ˆè¦æ±‚æ‰‹å‹•è¼¸å…¥
        for idx in needs_date:
            pf = parsed_files[idx]
            user_date = st.sidebar.date_input(
                f"æŒ‡å®š {pf['name']} çš„æ—¥æœŸ",
                key=f"pos_date_{idx}"
            )
            pf['date'] = pd.Timestamp(user_date)

        # æ‰€æœ‰æª”æ¡ˆéƒ½æœ‰æ—¥æœŸå¾Œï¼Œè¼‰å…¥
        all_have_dates = all(pf['date'] is not None for pf in parsed_files)

        if all_have_dates and len(parsed_files) > 0:
            try:
                files_list = []
                fallback_dates = []
                for pf in parsed_files:
                    pf['file'].seek(0)
                    files_list.append(pf['file'])
                    fallback_dates.append(pf['date'])

                schedule = loader.load_multi_positions(files_list, fallback_dates)
                st.session_state.position_schedule = schedule
                st.session_state.positions = schedule[0][1]  # ç¬¬ä¸€æœŸéƒ¨ä½

                if len(schedule) > 1:
                    st.session_state.multi_mode = True
                    diffs = _DL.compute_position_diffs(schedule)
                    st.session_state.position_diffs = diffs
                    st.sidebar.success(f"å·²è¼‰å…¥ {len(schedule)} æœŸéƒ¨ä½")
                    for s_date, s_df in schedule:
                        st.sidebar.caption(f"  {s_date.strftime('%Y-%m-%d')}: {len(s_df)} ç­†")
                else:
                    st.session_state.multi_mode = False
                    st.session_state.position_diffs = None
                    st.sidebar.success(f"å·²è¼‰å…¥ {len(schedule[0][1])} ç­†éƒ¨ä½ï¼ˆå»ºå€‰æ—¥ {schedule[0][0].strftime('%Y-%m-%d')}ï¼‰")

            except Exception as e:
                st.sidebar.error(f"éƒ¨ä½è¼‰å…¥å¤±æ•—ï¼š{e}")
                import traceback
                st.sidebar.code(traceback.format_exc())

    # ä½¿ç”¨ session state ä¸­çš„éƒ¨ä½
    if st.session_state.positions is not None:
        positions = st.session_state.positions

    # æ—¥æœŸè‡ªå‹•æ±ºå®šï¼šå»ºå€‰æ—¥ = schedule ç¬¬ä¸€å€‹å¿«ç…§æ—¥æœŸï¼ŒçµæŸæ—¥ = è‚¡åƒ¹æœ€å¾Œä¸€å¤©
    trading_dates = st.session_state.trading_dates

    if st.session_state.position_schedule and len(st.session_state.position_schedule) > 0:
        start_date = st.session_state.position_schedule[0][0].date()
    elif len(trading_dates) > 0:
        default_start_idx = max(0, len(trading_dates) - 60)
        start_date = trading_dates[default_start_idx].date()
    else:
        start_date = None

    end_date = trading_dates[-1].date() if len(trading_dates) > 0 else None

    # é¡¯ç¤ºé¸é …
    st.sidebar.subheader("2ï¸âƒ£ é¡¯ç¤ºé¸é …")

    show_etf_lookthrough = st.sidebar.checkbox("é¡¯ç¤º ETF look-through æ˜ç´°", value=False)
    show_reduction_detail = st.sidebar.checkbox("é¡¯ç¤ºæŠ˜æ¸›ä¾†æºåˆ†è§£", value=True)

    # ==========================================================================
    # åŸ·è¡Œå›æ¸¬
    # ==========================================================================
    st.sidebar.subheader("3ï¸âƒ£ åŸ·è¡Œ")

    if st.sidebar.button("ğŸš€ é–‹å§‹æ¨¡æ“¬", type="primary", use_container_width=True):
        if positions is None or len(positions) == 0:
            st.error("è«‹å…ˆä¸Šå‚³éƒ¨ä½æª”æ¡ˆ")
        elif start_date is None or end_date is None:
            st.error("è‚¡åƒ¹æ•¸æ“šå°šæœªè¼‰å…¥ï¼Œç„¡æ³•æ±ºå®šæ¨¡æ“¬æœŸé–“")
        else:
            try:
                engine = BacktestEngine(loader)

                # å–å¾—äº¤æ˜“æ—¥æ•¸ä»¥é¡¯ç¤ºé€²åº¦
                calc_dates = engine.get_trading_dates_range(
                    pd.Timestamp(start_date), pd.Timestamp(end_date)
                )
                total_days = len(calc_dates)

                # å»ºç«‹é€²åº¦æ¢
                progress_bar = st.progress(0, text="æ­£åœ¨åˆå§‹åŒ–...")
                status_text = st.empty()

                # ä½¿ç”¨é€²åº¦å›èª¿åŸ·è¡Œå›æ¸¬
                def progress_callback(current, total, date_str):
                    pct = current / total if total > 0 else 0
                    progress_bar.progress(pct, text=f"è¨ˆç®—ä¸­... {current}/{total} ({pct:.0%})")
                    status_text.text(f"æ­£åœ¨è¨ˆç®— {date_str}")

                # çµ±ä¸€èµ° position_schedule è·¯å¾‘
                if st.session_state.position_schedule:
                    results = engine.run(
                        position_schedule=st.session_state.position_schedule,
                        start_date=pd.Timestamp(start_date),
                        end_date=pd.Timestamp(end_date),
                        progress_callback=progress_callback
                    )
                else:
                    results = engine.run(
                        positions=positions,
                        start_date=pd.Timestamp(start_date),
                        end_date=pd.Timestamp(end_date),
                        progress_callback=progress_callback
                    )

                progress_bar.progress(1.0, text="è¨ˆç®—å®Œæˆï¼")
                status_text.empty()
                st.session_state.backtest_results = results
                st.success(f"è¨ˆç®—å®Œæˆï¼å…±è™•ç† {len(results.daily_results)} å€‹äº¤æ˜“æ—¥")
            except Exception as e:
                st.error(f"è¨ˆç®—å¤±æ•—ï¼š{e}")
                import traceback
                st.code(traceback.format_exc())

    # ==========================================================================
    # é¡¯ç¤ºéƒ¨ä½
    # ==========================================================================
    # å–å¾—è‚¡åƒ¹ï¼ˆç”¨æ–¼ä¼°ç®—å¸‚å€¼ï¼‰
    try:
        _prices_for_mv = loader.load_prices()
    except Exception:
        _prices_for_mv = None

    if positions is not None and len(positions) > 0:
        st.header("ğŸ“‹ éƒ¨ä½æ¸…å–®")

        # å¤šæœŸæ¨¡å¼
        if st.session_state.multi_mode and st.session_state.position_schedule and len(st.session_state.position_schedule) > 1:
            schedule = st.session_state.position_schedule

            # --- éƒ¨ä½è®Šå‹•æ‘˜è¦ ---
            diffs = st.session_state.position_diffs

            # å»ºç«‹ date â†’ snapshot df çš„å¿«é€ŸæŸ¥æ‰¾
            schedule_map = {pd.Timestamp(s_date): s_df for s_date, s_df in schedule}

            st.subheader("éƒ¨ä½è®Šå‹•æ‘˜è¦")
            summary_records = []

            # å…ˆåŠ å»ºå€‰æ—¥ï¼ˆschedule[0]ï¼‰
            s0_date, s0_df = schedule[0]
            mv0 = estimate_mv(s0_df, _prices_for_mv, as_of_date=s0_date)
            summary_records.append({
                'æ—¥æœŸ': s0_date.strftime('%Y-%m-%d'),
                'é¡å‹': 'å»ºå€‰',
                'å¤šæ–¹å¸‚å€¼': f"{mv0['long_mv']:,.0f}" if mv0 else '-',
                'ç©ºæ–¹å¸‚å€¼': f"{mv0['short_mv']:,.0f}" if mv0 else '-',
                'æ·¨å¸‚å€¼': f"{mv0['long_mv'] - mv0['short_mv']:+,.0f}" if mv0 else '-',
                'å¯¦ç¾æç›Š': '-', 'å‡ºé‡‘': '-',
                'æ–°å¢': '-', 'å¹³å€‰': '-', 'åŠ å€‰': '-',
                'æ¸›å€‰': '-', 'ç¿»å€‰': '-', 'è®Šå‹•ç­†æ•¸': '-',
            })

            # è‹¥æœ‰å›æ¸¬çµæœï¼Œå»ºç«‹ date â†’ event æŸ¥æ‰¾ï¼ˆå«å¯¦ç¾æç›Š/å‡ºé‡‘ï¼‰
            _bt_results = st.session_state.backtest_results
            _evt_map = {}
            if _bt_results and _bt_results.position_change_events:
                for evt in _bt_results.position_change_events:
                    _evt_map[pd.Timestamp(evt['date'])] = evt

            # å„æ¬¡è®Šå‹•
            if diffs:
                for d in diffs:
                    type_counts = d['diff_df']['è®Šå‹•é¡å‹'].value_counts().to_dict() if len(d['diff_df']) > 0 else {}
                    # æ‰¾è©²æ—¥æœŸå°æ‡‰çš„ snapshot ç®—å¸‚å€¼
                    snap_df = schedule_map.get(pd.Timestamp(d['date']))
                    mv = estimate_mv(snap_df, _prices_for_mv, as_of_date=d['date']) if snap_df is not None else None
                    # å¾å›æ¸¬çµæœå–å¯¦ç¾æç›Š/å‡ºé‡‘
                    evt = _evt_map.get(pd.Timestamp(d['date']))
                    summary_records.append({
                        'æ—¥æœŸ': d['date'].strftime('%Y-%m-%d'),
                        'é¡å‹': 'åŠ æ¸›å€‰',
                        'å¤šæ–¹å¸‚å€¼': f"{mv['long_mv']:,.0f}" if mv else '-',
                        'ç©ºæ–¹å¸‚å€¼': f"{mv['short_mv']:,.0f}" if mv else '-',
                        'æ·¨å¸‚å€¼': f"{mv['long_mv'] - mv['short_mv']:+,.0f}" if mv else '-',
                        'å¯¦ç¾æç›Š': f"{evt['realized_pnl']:+,.0f}" if evt else '-',
                        'å‡ºé‡‘': f"{evt['withdrawal']:,.0f}" if evt else '-',
                        'æ–°å¢': type_counts.get('æ–°å¢', 0),
                        'å¹³å€‰': type_counts.get('å¹³å€‰', 0),
                        'åŠ å€‰': type_counts.get('åŠ å€‰', 0),
                        'æ¸›å€‰': type_counts.get('æ¸›å€‰', 0),
                        'ç¿»å€‰': type_counts.get('ç¿»å€‰', 0),
                        'è®Šå‹•ç­†æ•¸': len(d['diff_df']),
                    })

            st.dataframe(pd.DataFrame(summary_records), use_container_width=True, hide_index=True)

            # --- å„æœŸéƒ¨ä½ tabs ---
            tab_labels = []
            for t_idx, (s_date, s_df) in enumerate(schedule):
                label = f"{s_date.strftime('%Y-%m-%d')}"
                if t_idx == 0:
                    label += " (å»ºå€‰)"
                tab_labels.append(label)

            pos_tabs = st.tabs(tab_labels)

            for t_idx, (s_date, s_df) in enumerate(schedule):
                with pos_tabs[t_idx]:
                    mv_info = estimate_mv(s_df, _prices_for_mv, as_of_date=s_date)
                    if mv_info:
                        c1, c2, c3, c4, c5 = st.columns(5)
                        with c1:
                            st.metric("å¤šæ–¹", f"{mv_info['long_count']} æª”")
                        with c2:
                            st.metric("å¤šæ–¹å¸‚å€¼", f"{mv_info['long_mv']:,.0f}")
                        with c3:
                            st.metric("ç©ºæ–¹", f"{mv_info['short_count']} æª”")
                        with c4:
                            st.metric("ç©ºæ–¹å¸‚å€¼", f"{mv_info['short_mv']:,.0f}")
                        with c5:
                            net = mv_info['long_mv'] - mv_info['short_mv']
                            st.metric("æ·¨å¸‚å€¼", f"{net:+,.0f}")
                    else:
                        c1, c2, c3 = st.columns(3)
                        with c1:
                            st.metric("å¤šæ–¹", f"{len(s_df[s_df['side']=='LONG'])} æª”")
                        with c2:
                            st.metric("ç©ºæ–¹", f"{len(s_df[s_df['side']=='SHORT'])} æª”")
                        with c3:
                            st.metric("ç¸½éƒ¨ä½", f"{len(s_df)} ç­†")

                    # è‹¥æœ‰å°æ‡‰çš„å·®ç•°è³‡æ–™ï¼Œé¡¯ç¤ºè©²æœŸè®Šå‹•
                    if diffs and t_idx > 0 and t_idx - 1 < len(diffs):
                        diff_df = diffs[t_idx - 1]['diff_df']
                        if len(diff_df) > 0:
                            st.caption("èˆ‡å‰æœŸå·®ç•°ï¼š")
                            st.dataframe(diff_df, use_container_width=True, height=180, hide_index=True)

                    st.dataframe(s_df, use_container_width=True, height=250)
        else:
            # å–®æœŸæ¨¡å¼
            as_of = start_date if start_date else None
            mv_info = estimate_mv(positions, _prices_for_mv, as_of_date=as_of)
            if mv_info:
                c1, c2, c3, c4, c5 = st.columns(5)
                with c1:
                    st.metric("å¤šæ–¹", f"{mv_info['long_count']} æª”")
                with c2:
                    st.metric("å¤šæ–¹å¸‚å€¼", f"{mv_info['long_mv']:,.0f}")
                with c3:
                    st.metric("ç©ºæ–¹", f"{mv_info['short_count']} æª”")
                with c4:
                    st.metric("ç©ºæ–¹å¸‚å€¼", f"{mv_info['short_mv']:,.0f}")
                with c5:
                    net = mv_info['long_mv'] - mv_info['short_mv']
                    st.metric("æ·¨å¸‚å€¼", f"{net:+,.0f}")
            else:
                c1, c2, c3 = st.columns(3)
                with c1:
                    st.metric("å¤šæ–¹", f"{len(positions[positions['side']=='LONG'])} æª”")
                with c2:
                    st.metric("ç©ºæ–¹", f"{len(positions[positions['side']=='SHORT'])} æª”")
                with c3:
                    st.metric("ç¸½éƒ¨ä½", f"{len(positions)} ç­†")

            with st.expander("æŸ¥çœ‹éƒ¨ä½æ˜ç´°", expanded=False):
                st.dataframe(positions, use_container_width=True)

    # ==========================================================================
    # é¡¯ç¤ºçµæœ
    # ==========================================================================
    if st.session_state.backtest_results is not None:
        results = st.session_state.backtest_results

        st.header("ğŸ“Š æ¨¡æ“¬çµæœ")

        # é©—è­‰ç‹€æ…‹
        if not results.verification_passed:
            st.markdown('<div class="error-card">', unsafe_allow_html=True)
            st.error("âš ï¸ é©—è­‰ç™¼ç¾å•é¡Œ")
            for err in results.verification_errors:
                st.write(f"- {err}")
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.success("âœ… æ‰€æœ‰é©—è­‰é€šé")

        # æ ¸å¿ƒæŒ‡æ¨™
        ts = results.timeseries_df

        if len(ts) > 0:
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    "æœ€æ–° IM",
                    f"{ts['IM_today'].iloc[-1]:,.0f}",
                    delta=f"{ts['IM_today'].iloc[-1] - ts['IM_today'].iloc[0]:,.0f}"
                )

            with col2:
                st.metric(
                    "æœ€æ–° MM (70%)",
                    f"{ts['MM_today'].iloc[-1]:,.0f}"
                )

            with col3:
                margin_call_count = ts['margin_call_flag'].sum()
                st.metric(
                    "è¿½ç¹³æ¬¡æ•¸",
                    f"{margin_call_count}",
                    delta="éœ€æ³¨æ„" if margin_call_count > 0 else None,
                    delta_color="inverse"
                )

            with col4:
                st.metric(
                    "å¹³å‡ Gross æ§“æ¡¿",
                    f"{ts['Gross_Lev'].mean():.2f}x"
                )

            # åœ–è¡¨
            st.subheader("ğŸ“ˆ æ™‚åºåœ–è¡¨")

            # æ±ºå®šæ˜¯å¦é¡¯ç¤ºéƒ¨ä½è®Šå‹•é ç±¤
            has_pos_changes = (
                st.session_state.position_diffs is not None
                and len(st.session_state.position_diffs) > 0
            )

            tab_names = ["IM/MM/Equity", "å¸‚å€¼è®ŠåŒ–", "æŠ˜æ¸›åˆ†è§£"]
            if has_pos_changes:
                tab_names.append("éƒ¨ä½è®Šå‹•")
                tab_names.append("è³‡é‡‘æµå‘")

            chart_tabs = st.tabs(tab_names)

            with chart_tabs[0]:
                fig = create_timeseries_chart(ts)
                st.plotly_chart(fig, use_container_width=True)

            with chart_tabs[1]:
                fig = create_mv_chart(ts)
                st.plotly_chart(fig, use_container_width=True)

            with chart_tabs[2]:
                if show_reduction_detail:
                    fig = create_reduction_chart(ts)
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("è«‹åœ¨å´é‚Šæ¬„å‹¾é¸ã€Œé¡¯ç¤ºæŠ˜æ¸›ä¾†æºåˆ†è§£ã€")

            if has_pos_changes:
                with chart_tabs[3]:
                    st.markdown("### éƒ¨ä½è®Šå‹•æ™‚é–“ç·š")

                    # è®Šå‹•æ™‚é–“ç·šè¡¨æ ¼
                    schedule = st.session_state.position_schedule
                    # å»ºç«‹ event æŸ¥æ‰¾
                    _change_evt_map = {}
                    if results.position_change_events:
                        for evt in results.position_change_events:
                            _change_evt_map[pd.Timestamp(evt['date'])] = evt

                    timeline_records = []
                    for t_idx, (s_date, s_df) in enumerate(schedule):
                        long_count = len(s_df[s_df['side'] == 'LONG'])
                        short_count = len(s_df[s_df['side'] == 'SHORT'])
                        evt = _change_evt_map.get(pd.Timestamp(s_date))
                        rec = {
                            'å¿«ç…§æ—¥æœŸ': s_date.strftime('%Y-%m-%d'),
                            'å¤šæ–¹æ•¸é‡': long_count,
                            'ç©ºæ–¹æ•¸é‡': short_count,
                            'ç¸½éƒ¨ä½æ•¸': len(s_df),
                        }
                        if t_idx == 0:
                            rec['æ–° IM'] = f"{results.timeseries_df.iloc[0]['IM_today']:,.0f}" if len(results.timeseries_df) > 0 else '-'
                            rec['è®Šå‹•æ™‚æ¬Šç›Š'] = '-'
                            rec['å¯¦ç¾æç›Š'] = '-'
                            rec['å‡ºé‡‘'] = '-'
                        elif evt:
                            rec['æ–° IM'] = f"{evt['new_im']:,.0f}"
                            rec['è®Šå‹•æ™‚æ¬Šç›Š'] = f"{evt['equity_at_change']:,.0f}"
                            rec['å¯¦ç¾æç›Š'] = f"{evt['realized_pnl']:+,.0f}"
                            rec['å‡ºé‡‘'] = f"{evt['withdrawal']:,.0f}"
                        else:
                            rec['æ–° IM'] = '-'
                            rec['è®Šå‹•æ™‚æ¬Šç›Š'] = '-'
                            rec['å¯¦ç¾æç›Š'] = '-'
                            rec['å‡ºé‡‘'] = '-'
                        timeline_records.append(rec)

                    timeline_df = pd.DataFrame(timeline_records)
                    st.dataframe(timeline_df, use_container_width=True, hide_index=True)

                    # é€æœŸå·®ç•°è¡¨
                    st.markdown("### é€æœŸå·®ç•°æ˜ç´°")
                    diffs = st.session_state.position_diffs
                    diff_tab_names = [
                        f"{d['prev_date'].strftime('%m/%d')} â†’ {d['date'].strftime('%m/%d')}"
                        for d in diffs
                    ]
                    diff_tabs = st.tabs(diff_tab_names)

                    for d_idx, diff_info in enumerate(diffs):
                        with diff_tabs[d_idx]:
                            diff_df = diff_info['diff_df']
                            st.caption(
                                f"å¾ {diff_info['prev_date'].strftime('%Y-%m-%d')} "
                                f"åˆ° {diff_info['date'].strftime('%Y-%m-%d')} çš„è®Šå‹•"
                            )
                            if len(diff_df) > 0:
                                # è®Šå‹•é¡å‹æ‘˜è¦
                                type_counts = diff_df['è®Šå‹•é¡å‹'].value_counts()
                                summary_cols = st.columns(min(len(type_counts), 6))
                                for ci, (change_type, count) in enumerate(type_counts.items()):
                                    with summary_cols[ci % len(summary_cols)]:
                                        st.metric(change_type, f"{count} ç­†")

                                st.dataframe(diff_df, use_container_width=True, hide_index=True)
                            else:
                                st.info("ç„¡éƒ¨ä½è®Šå‹•")

                with chart_tabs[4]:
                    st.markdown("### è³‡é‡‘æµå‘åˆ†æ")

                    if results.position_change_events:
                        # å»ºç«‹å­é ç±¤ï¼šæ¯æ¬¡è®Šå‹•ä¸€å€‹
                        flow_tab_names = []
                        for evt_idx, evt in enumerate(results.position_change_events):
                            evt_date_str = evt['date'].strftime('%m/%d')
                            # æ‰¾å‰ä¸€å€‹æ—¥æœŸ
                            if evt_idx == 0:
                                schedule = st.session_state.position_schedule
                                prev_date_str = schedule[0][0].strftime('%m/%d')
                            else:
                                prev_date_str = results.position_change_events[evt_idx - 1]['date'].strftime('%m/%d')
                            flow_tab_names.append(f"{prev_date_str} â†’ {evt_date_str}")

                        flow_tabs = st.tabs(flow_tab_names)

                        for evt_idx, evt in enumerate(results.position_change_events):
                            with flow_tabs[evt_idx]:
                                evt_date_str = evt['date'].strftime('%Y-%m-%d')

                                # --- å€å¡Š Aï¼šè®Šå‹•å‰å¾Œæ¯”è¼ƒè¡¨ ---
                                st.markdown(f"#### è®Šå‹•å‰å¾Œæ¯”è¼ƒï¼ˆ{evt_date_str}ï¼‰")

                                old_long_mv = evt.get('old_long_mv', 0)
                                old_short_mv = evt.get('old_short_mv', 0)
                                new_long_mv = evt.get('long_mv', 0)
                                new_short_mv = evt.get('short_mv', 0)
                                old_im = evt.get('old_im', 0)
                                new_im = evt.get('new_im', 0)
                                old_mm = evt.get('old_mm', 0)
                                new_mm = evt.get('new_mm', 0)

                                compare_data = {
                                    'é …ç›®': ['å¤šæ–¹ MV', 'ç©ºæ–¹ MV', 'IM', 'MM'],
                                    'è®Šå‹•å‰': [
                                        f"{old_long_mv:,.0f}",
                                        f"{old_short_mv:,.0f}",
                                        f"{old_im:,.0f}",
                                        f"{old_mm:,.0f}",
                                    ],
                                    'è®Šå‹•å¾Œ': [
                                        f"{new_long_mv:,.0f}",
                                        f"{new_short_mv:,.0f}",
                                        f"{new_im:,.0f}",
                                        f"{new_mm:,.0f}",
                                    ],
                                    'å·®ç•°': [
                                        f"{new_long_mv - old_long_mv:+,.0f}",
                                        f"{new_short_mv - old_short_mv:+,.0f}",
                                        f"{new_im - old_im:+,.0f}",
                                        f"{new_mm - old_mm:+,.0f}",
                                    ],
                                }
                                st.dataframe(
                                    pd.DataFrame(compare_data),
                                    use_container_width=True,
                                    hide_index=True
                                )

                                # --- å€å¡Š Bï¼šè³‡é‡‘æµå‘ç€‘å¸ƒ ---
                                st.markdown("#### è³‡é‡‘æµå‘")

                                equity_before = evt.get('equity_before_change', 0)
                                realized_pnl = evt.get('realized_pnl', 0)
                                withdrawal = evt.get('withdrawal', 0)
                                equity_after = evt.get('equity_at_change', 0)

                                # å¯å‡ºé‡‘é‡‘é¡è¨ˆç®—å…¬å¼
                                excess_over_im = max(0, equity_before - new_im)
                                max_withdrawal = min(realized_pnl, excess_over_im) if realized_pnl > 0 else 0

                                flow_md = f"""
| æ­¥é©Ÿ | èªªæ˜ | é‡‘é¡ |
|------|------|-----:|
| 1 | è®Šå‹•å‰æ¬Šç›Šï¼ˆèˆŠéƒ¨ä½ä»¥ç•¶æ—¥åƒ¹æ ¼çµç®—ï¼‰ | **{equity_before:,.0f}** |
| 2 | å¯¦ç¾æç›Šï¼ˆå¹³/æ¸›å€‰éƒ¨ä½æŒ‰åŸºæº–åƒ¹å·®è¨ˆç®—ï¼‰ | **{realized_pnl:+,.0f}** |
| 3 | å¯å‡ºé‡‘é‡‘é¡ = min(å¯¦ç¾æç›Š, max(0, æ¬Šç›Š - æ–°IM)) | **{max_withdrawal:,.0f}** |
| 4 | å¯¦éš›å‡ºé‡‘ | **-{withdrawal:,.0f}** |
| 5 | å‡ºé‡‘å¾Œæ¬Šç›Š | **{equity_after:,.0f}** |
"""
                                st.markdown(flow_md)

                                # --- å€å¡Š B2ï¼šå‡ºé‡‘ä¾†æº â€” é€éƒ¨ä½å¯¦ç¾æç›Šæ˜ç´° ---
                                pnl_details = evt.get('realized_pnl_details', [])
                                if pnl_details:
                                    st.markdown("#### å‡ºé‡‘ä¾†æº â€” é€éƒ¨ä½å¯¦ç¾æç›Šæ˜ç´°")
                                    detail_records = []
                                    for d in pnl_details:
                                        side_label = 'å¤š' if d['side'] == 'LONG' else 'ç©º'
                                        detail_records.append({
                                            'ä»£è™Ÿ': d['code'],
                                            'æ–¹å‘': side_label,
                                            'è®Šå‹•': d['change_type'],
                                            'åŸæ•¸é‡': f"{d['old_qty']:,}",
                                            'æ–°æ•¸é‡': f"{d['new_qty']:,}",
                                            'å¹³/æ¸›é‡': f"{d['closed_qty']:,}",
                                            'åŸºæº–åƒ¹': f"{d['base_price']:.2f}",
                                            'ç•¶æ—¥åƒ¹': f"{d['current_price']:.2f}",
                                            'åƒ¹å·®': f"{d['current_price'] - d['base_price']:+.2f}" if d['side'] == 'LONG' else f"{d['base_price'] - d['current_price']:+.2f}",
                                            'å¯¦ç¾æç›Š': f"{d['pnl']:+,.0f}",
                                        })
                                    detail_df = pd.DataFrame(detail_records)
                                    st.dataframe(detail_df, use_container_width=True, hide_index=True)

                                    # å°è¨ˆ
                                    total_pnl = sum(d['pnl'] for d in pnl_details)
                                    profit_count = sum(1 for d in pnl_details if d['pnl'] > 0)
                                    loss_count = sum(1 for d in pnl_details if d['pnl'] < 0)
                                    profit_sum = sum(d['pnl'] for d in pnl_details if d['pnl'] > 0)
                                    loss_sum = sum(d['pnl'] for d in pnl_details if d['pnl'] < 0)

                                    sc1, sc2, sc3, sc4 = st.columns(4)
                                    with sc1:
                                        st.metric("ç²åˆ©éƒ¨ä½", f"{profit_count} æª”", delta=f"{profit_sum:+,.0f}")
                                    with sc2:
                                        st.metric("è™§æéƒ¨ä½", f"{loss_count} æª”", delta=f"{loss_sum:+,.0f}", delta_color="inverse")
                                    with sc3:
                                        st.metric("å¯¦ç¾æç›Šåˆè¨ˆ", f"{total_pnl:+,.0f}")
                                    with sc4:
                                        st.metric("å¯¦éš›å‡ºé‡‘", f"{withdrawal:,.0f}")
                                elif realized_pnl == 0:
                                    st.caption("æœ¬æ¬¡è®Šå‹•ç„¡å¹³å€‰/æ¸›å€‰éƒ¨ä½ï¼Œç„¡å¯¦ç¾æç›Šã€‚")

                                # --- å€å¡Š Cï¼šèè³‡é‡‘é¡è®ŠåŒ– ---
                                st.markdown("#### èè³‡é‡‘é¡è®ŠåŒ–")

                                old_long_fin = evt.get('old_long_financing', 0)
                                old_short_fin = evt.get('old_short_financing', 0)
                                new_long_fin = evt.get('new_long_financing', 0)
                                new_short_fin = evt.get('new_short_financing', 0)
                                old_total_fin = old_long_fin + old_short_fin
                                new_total_fin = new_long_fin + new_short_fin

                                fin_data = {
                                    'é …ç›®': ['å¤šæ–¹èè³‡', 'ç©ºæ–¹èè³‡', 'ç¸½èè³‡'],
                                    'è®Šå‹•å‰': [
                                        f"{old_long_fin:,.0f}",
                                        f"{old_short_fin:,.0f}",
                                        f"{old_total_fin:,.0f}",
                                    ],
                                    'è®Šå‹•å¾Œ': [
                                        f"{new_long_fin:,.0f}",
                                        f"{new_short_fin:,.0f}",
                                        f"{new_total_fin:,.0f}",
                                    ],
                                    'å·®ç•°': [
                                        f"{new_long_fin - old_long_fin:+,.0f}",
                                        f"{new_short_fin - old_short_fin:+,.0f}",
                                        f"{new_total_fin - old_total_fin:+,.0f}",
                                    ],
                                    'èªªæ˜': [
                                        'å¤šæ–¹MV - å¸³ä¸Šè³‡é‡‘',
                                        'å€Ÿåˆ¸å…¨é¡',
                                        '',
                                    ],
                                }
                                st.dataframe(
                                    pd.DataFrame(fin_data),
                                    use_container_width=True,
                                    hide_index=True
                                )

                                st.info(
                                    "å‡ºé‡‘ä½¿å¸³ä¸Šè³‡é‡‘æ¸›å°‘ï¼Œåˆ¸å•†éœ€å¤šèå‡ºè³‡é‡‘ä»¥ç¶­æŒå¤šæ–¹å¸‚å€¼ã€‚"
                                    "ç©ºæ–¹èè³‡ = å€Ÿåˆ¸å¸‚å€¼ï¼Œéš¨éƒ¨ä½MVè®Šå‹•ã€‚"
                                )

                                # --- å€å¡Š Dï¼šè¦å‰‡èªªæ˜ ---
                                with st.expander("è¨ˆç®—è¦å‰‡èªªæ˜"):
                                    st.markdown("""
- **IM é‡ç®—é‚è¼¯**ï¼šéƒ¨ä½è®Šå‹•å¾Œï¼Œä»¥æ–°éƒ¨ä½é‡æ–°è¨ˆç®— IMï¼ˆå«åˆ†é‚Šã€å¤§å°é‚Šã€å°æ²–æŠ˜æ¸›ï¼‰
- **MM = æ–° IM x 70%**ï¼šéƒ¨ä½è®Šå‹•å¾Œ MM é‡ç½®ç‚ºæ–° IM çš„ 70%
- **å‡ºé‡‘è¦å‰‡**ï¼šåƒ…å°±ã€Œå·²å¹³å€‰/æ¸›å€‰éƒ¨ä½çš„å¯¦ç¾æç›Šã€å¯å‡ºé‡‘ï¼Œä¸”å‡ºé‡‘å¾Œæ¬Šç›Šä¸ä½æ–¼æ–° IM
  - å¯å‡ºé‡‘é‡‘é¡ = min(å¯¦ç¾æç›Š, max(0, æ¬Šç›Š - æ–°IM))
- **èè³‡å…¬å¼**ï¼š
  - å¤šæ–¹èè³‡ = max(0, å¤šæ–¹MV - å¸³ä¸Šè³‡é‡‘)
  - ç©ºæ–¹èè³‡ = ç©ºæ–¹MVï¼ˆå€Ÿåˆ¸è³£å‡ºå…¨é¡èè³‡ï¼‰
- **è¿½ç¹³**ï¼šè‹¥å‡ºé‡‘å¾Œæ¬Šç›Š < MM â†’ ç«‹å³è¿½ç¹³è‡³æ–° IM
""")
                    else:
                        st.info("ç„¡éƒ¨ä½è®Šå‹•äº‹ä»¶")

            # é€æ—¥æ˜ç´°è¡¨ - æ‹†æˆå…©å€‹è¡¨
            st.subheader("ğŸ“‹ é€æ—¥æ˜ç´°")

            # æ ¼å¼åŒ–é¡¯ç¤º
            display_df = ts.copy()
            display_df['date'] = display_df['date'].dt.strftime('%Y-%m-%d')

            # ===== è¡¨1: æ¬Šç›Šèˆ‡æç›Šè¿½è¹¤ =====
            st.markdown("**è¡¨1ï¼šæ¬Šç›Šèˆ‡æç›Šè¿½è¹¤**")
            equity_cols = ['date', 'Long_MV', 'Short_MV',
                          'Daily_PnL_Long', 'Daily_PnL_Short', 'Daily_PnL',
                          'Cum_PnL_Long', 'Cum_PnL_Short', 'Cumulative_PnL',
                          'Equity_Before', 'MM_At_Call', 'IM_today',
                          'margin_call_flag', 'Required_Deposit', 'Withdrawal', 'Equity', 'MM_today']
            equity_df = display_df[[c for c in equity_cols if c in display_df.columns]].copy()

            # æ ¼å¼åŒ–é‡‘é¡
            money_cols_1 = ['Long_MV', 'Short_MV',
                           'Daily_PnL_Long', 'Daily_PnL_Short', 'Daily_PnL',
                           'Cum_PnL_Long', 'Cum_PnL_Short', 'Cumulative_PnL',
                           'Equity_Before', 'MM_At_Call', 'IM_today', 'Required_Deposit',
                           'Withdrawal', 'Equity', 'MM_today']
            for col in money_cols_1:
                if col in equity_df.columns:
                    equity_df[col] = equity_df[col].apply(lambda x: f"{x:,.0f}")

            # é‡å‘½åæ¬„ä½
            equity_df = equity_df.rename(columns={
                'date': 'æ—¥æœŸ', 'Long_MV': 'å¤šæ–¹MV', 'Short_MV': 'ç©ºæ–¹MV',
                'Daily_PnL_Long': 'å¤šæ–¹æ—¥æç›Š', 'Daily_PnL_Short': 'ç©ºæ–¹æ—¥æç›Š', 'Daily_PnL': 'åˆè¨ˆæ—¥æç›Š',
                'Cum_PnL_Long': 'å¤šæ–¹ç´¯è¨ˆ', 'Cum_PnL_Short': 'ç©ºæ–¹ç´¯è¨ˆ', 'Cumulative_PnL': 'åˆè¨ˆç´¯è¨ˆ',
                'Equity_Before': 'æ¬Šç›Š(åˆ¤å®š)', 'MM_At_Call': 'MM(åˆ¤å®š)', 'IM_today': 'IM',
                'margin_call_flag': 'è¿½ç¹³', 'Required_Deposit': 'è¿½ç¹³é‡‘é¡',
                'Withdrawal': 'å‡ºé‡‘', 'Equity': 'æ¬Šç›Š(è£œå¾Œ)', 'MM_today': 'MM(è£œå¾Œ)'
            })

            st.dataframe(equity_df, use_container_width=True, height=300)

            # ===== è¡¨2: ä¿è­‰é‡‘è¨ˆç®—æ˜ç´° =====
            st.markdown("**è¡¨2ï¼šä¿è­‰é‡‘è¨ˆç®—æ˜ç´°**")
            margin_cols = ['date', 'Base_IM_long', 'Base_IM_short', 'IM_big', 'IM_small_before',
                          'reduction_etf_100', 'reduction_same_bucket', 'reduction_cross_bucket',
                          'total_reduction', 'IM_small_after', 'IM_today', 'Gross_Lev', 'Raw_Lev']
            margin_df = display_df[[c for c in margin_cols if c in display_df.columns]].copy()

            # æ ¼å¼åŒ–é‡‘é¡
            money_cols_2 = ['Base_IM_long', 'Base_IM_short', 'IM_big', 'IM_small_before',
                           'reduction_etf_100', 'reduction_same_bucket', 'reduction_cross_bucket',
                           'total_reduction', 'IM_small_after', 'IM_today']
            for col in money_cols_2:
                if col in margin_df.columns:
                    margin_df[col] = margin_df[col].apply(lambda x: f"{x:,.0f}")

            # é‡å‘½åæ¬„ä½
            margin_df = margin_df.rename(columns={
                'date': 'æ—¥æœŸ', 'Base_IM_long': 'å¤šæ–¹Base_IM', 'Base_IM_short': 'ç©ºæ–¹Base_IM',
                'IM_big': 'IMå¤§é‚Š', 'IM_small_before': 'IMå°é‚Š(æŠ˜å‰)',
                'reduction_etf_100': 'ETFæŠ˜æ¸›', 'reduction_same_bucket': 'åŒæ¡¶æŠ˜æ¸›',
                'reduction_cross_bucket': 'è·¨æ¡¶æŠ˜æ¸›', 'total_reduction': 'ç¸½æŠ˜æ¸›',
                'IM_small_after': 'IMå°é‚Š(æŠ˜å¾Œ)', 'IM_today': 'IM_today',
                'Gross_Lev': 'Grossæ§“æ¡¿', 'Raw_Lev': 'ç„¡æŠ˜æ¸›æ§“æ¡¿'
            })

            st.dataframe(margin_df, use_container_width=True, height=300)

            # ===== è¡¨3: èè³‡è²»ç”¨æ˜ç´° =====
            st.markdown("**è¡¨3ï¼šèè³‡è²»ç”¨æ˜ç´°**")
            st.caption("å¤šæ–¹èè³‡ = å¤šæ–¹MV - IMï½œç©ºæ–¹èè³‡ = ç©ºæ–¹MVï¼ˆå€Ÿåˆ¸è³£å‡ºä¸ç¹³ä¿è­‰é‡‘ï¼‰ï½œå®¢æˆ¶åˆ©ç‡ 3%ï½œåˆ¸å•†æ”¶ç›Š = å¤šæ–¹èè³‡Ã—1.2% + ç©ºæ–¹èè³‡Ã—3%ï½œåˆ©æ¯æŒ‰æ—¥æ›†æ—¥è¨ˆç®—")

            financing_cols = ['date', 'Long_MV', 'Short_MV', 'IM_today',
                             'Long_Financing', 'Short_Financing', 'Financing_Amount',
                             'Daily_Interest', 'Cumulative_Interest',
                             'Daily_Broker_Profit', 'Cumulative_Broker_Profit']
            financing_df = display_df[[c for c in financing_cols if c in display_df.columns]].copy()

            # æ ¼å¼åŒ–é‡‘é¡
            money_cols_3 = ['Long_MV', 'Short_MV', 'IM_today', 'Long_Financing', 'Short_Financing',
                           'Financing_Amount', 'Daily_Interest', 'Cumulative_Interest',
                           'Daily_Broker_Profit', 'Cumulative_Broker_Profit']
            for col in money_cols_3:
                if col in financing_df.columns:
                    financing_df[col] = financing_df[col].apply(lambda x: f"{x:,.0f}")

            # é‡å‘½åæ¬„ä½
            financing_df = financing_df.rename(columns={
                'date': 'æ—¥æœŸ', 'Long_MV': 'å¤šæ–¹MV', 'Short_MV': 'ç©ºæ–¹MV', 'IM_today': 'IM',
                'Long_Financing': 'å¤šæ–¹èè³‡', 'Short_Financing': 'ç©ºæ–¹èè³‡',
                'Financing_Amount': 'ç¸½èè³‡',
                'Daily_Interest': 'ç•¶æ—¥åˆ©æ¯', 'Cumulative_Interest': 'ç´¯è¨ˆåˆ©æ¯',
                'Daily_Broker_Profit': 'ç•¶æ—¥åˆ¸å•†æ”¶ç›Š', 'Cumulative_Broker_Profit': 'ç´¯è¨ˆåˆ¸å•†æ”¶ç›Š'
            })

            st.dataframe(financing_df, use_container_width=True, height=300)

            # èè³‡æ‘˜è¦
            if len(ts) > 0:
                last_day = ts.iloc[-1]
                fin_col1, fin_col2, fin_col3, fin_col4 = st.columns(4)
                with fin_col1:
                    st.metric("æœ€æ–°èè³‡é‡‘é¡", f"{last_day['Financing_Amount']:,.0f}")
                with fin_col2:
                    st.metric("ç´¯è¨ˆåˆ©æ¯æ”¯å‡º", f"{last_day['Cumulative_Interest']:,.0f}")
                with fin_col3:
                    st.metric("åˆ¸å•†ç´¯è¨ˆæ”¶ç›Š", f"{last_day['Cumulative_Broker_Profit']:,.0f}")
                with fin_col4:
                    # è¨ˆç®—å¹´åŒ–å ±é…¬ç‡
                    days = len(ts)
                    if days > 0 and last_day['Financing_Amount'] > 0:
                        annualized_cost = (last_day['Cumulative_Interest'] / last_day['Financing_Amount']) * (365 / days) * 100
                        st.metric("å¹´åŒ–èè³‡æˆæœ¬", f"{annualized_cost:.2f}%")

            # å»ºå€‰æ—¥åŠè¿½ç¹³æ—¥å¤šç©ºé…å°èˆ‡æ¸›æ”¶æ˜ç´°
            if results.daily_results:
                st.subheader("ğŸ”„ å¤šç©ºé…å°èˆ‡æ¸›æ”¶æ˜ç´°")

                # æ‰¾å‡ºéœ€è¦é¡¯ç¤ºçš„æ—¥æœŸï¼šå»ºå€‰æ—¥ + æ‰€æœ‰è¿½ç¹³æ—¥
                display_dates = []

                # å»ºå€‰æ—¥
                first_result = results.daily_results[0]
                display_dates.append(('å»ºå€‰æ—¥', first_result))

                # è¿½ç¹³æ—¥
                for dr in results.daily_results[1:]:
                    if dr.margin_result.margin_call:
                        date_str = dr.date.strftime('%Y-%m-%d')
                        display_dates.append((f'è¿½ç¹³æ—¥ {date_str}', dr))

                # ä½¿ç”¨ tabs é¡¯ç¤ºå„æ—¥æœŸçš„æ˜ç´°
                if len(display_dates) > 1:
                    tab_names = [d[0] for d in display_dates]
                    tabs = st.tabs(tab_names)

                    for i, (label, dr) in enumerate(display_dates):
                        with tabs[i]:
                            hedge_df = dr.margin_result.hedge_pairing_df
                            mr = dr.margin_result

                            st.markdown(f"**{label}** - {dr.date.strftime('%Y-%m-%d')}")

                            if len(hedge_df) > 0:
                                # é¡¯ç¤ºæ‘˜è¦çµ±è¨ˆ
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    paired_count = len(hedge_df[hedge_df['é…å°MV'] > 0])
                                    st.metric("é…å°æ¨™çš„æ•¸", f"{paired_count} æª”")
                                with col2:
                                    total_hedged = hedge_df['é…å°MV'].sum()
                                    st.metric("ç¸½é…å°MV", f"{total_hedged:,.0f}")
                                with col3:
                                    total_reduction = hedge_df['æ¸›æ”¶IM'].sum()
                                    st.metric("ç¸½æ¸›æ”¶IM", f"{total_reduction:,.0f}")
                                with col4:
                                    st.metric("ç•¶æ—¥IM", f"{mr.im_today:,.0f}")

                                # é¡¯ç¤ºæ˜ç´°è¡¨
                                st.dataframe(hedge_df, use_container_width=True, height=250)

                                # é¡¯ç¤ºæŠ˜æ¸›ä¾†æºåˆ†è§£
                                st.markdown("**æŠ˜æ¸›ä¾†æºåˆ†è§£ï¼š**")
                                breakdown_col1, breakdown_col2, breakdown_col3 = st.columns(3)
                                with breakdown_col1:
                                    st.metric("ETFå®Œå…¨å°æ²–(100%)", f"{mr.reduction_etf_100:,.0f}")
                                with breakdown_col2:
                                    st.metric("åŒæ¡¶å°æ²–", f"{mr.reduction_same_bucket:,.0f}")
                                with breakdown_col3:
                                    st.metric("è·¨æ¡¶å°æ²–", f"{mr.reduction_cross_bucket:,.0f}")
                            else:
                                st.info("ç„¡å¤šç©ºé…å°")
                else:
                    # åªæœ‰å»ºå€‰æ—¥ï¼Œä¸éœ€è¦ tabs
                    hedge_df = first_result.margin_result.hedge_pairing_df
                    mr = first_result.margin_result

                    st.markdown(f"**å»ºå€‰æ—¥** - {first_result.date.strftime('%Y-%m-%d')}")

                    if len(hedge_df) > 0:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            paired_count = len(hedge_df[hedge_df['é…å°MV'] > 0])
                            st.metric("é…å°æ¨™çš„æ•¸", f"{paired_count} æª”")
                        with col2:
                            total_hedged = hedge_df['é…å°MV'].sum()
                            st.metric("ç¸½é…å°MV", f"{total_hedged:,.0f}")
                        with col3:
                            total_reduction = hedge_df['æ¸›æ”¶IM'].sum()
                            st.metric("ç¸½æ¸›æ”¶IM", f"{total_reduction:,.0f}")

                        st.dataframe(hedge_df, use_container_width=True, height=300)

                        st.markdown("**æŠ˜æ¸›ä¾†æºåˆ†è§£ï¼š**")
                        breakdown_col1, breakdown_col2, breakdown_col3 = st.columns(3)
                        with breakdown_col1:
                            st.metric("ETFå®Œå…¨å°æ²–(100%)", f"{mr.reduction_etf_100:,.0f}")
                        with breakdown_col2:
                            st.metric("åŒæ¡¶å°æ²–", f"{mr.reduction_same_bucket:,.0f}")
                        with breakdown_col3:
                            st.metric("è·¨æ¡¶å°æ²–", f"{mr.reduction_cross_bucket:,.0f}")
                    else:
                        st.info("ç„¡å¤šç©ºé…å°")

            # ETF Look-through æ˜ç´°
            if show_etf_lookthrough and results.daily_results:
                st.subheader("ğŸ” ETF Look-through æ˜ç´°")
                first_result = results.daily_results[0]
                atom_df = first_result.margin_result.atom_detail_df

                if len(atom_df[atom_df['is_from_etf'] == True]) > 0:
                    etf_atoms = atom_df[atom_df['is_from_etf'] == True][
                        ['origin', 'parent', 'code', 'side', 'mv', 'leverage', 'base_im', 'bucket']
                    ].copy()
                    etf_atoms['mv'] = etf_atoms['mv'].apply(lambda x: f"{x:,.0f}")
                    etf_atoms['base_im'] = etf_atoms['base_im'].apply(lambda x: f"{x:,.0f}")
                    st.dataframe(etf_atoms, use_container_width=True)
                else:
                    st.info("ç›®å‰éƒ¨ä½ç„¡ ETF look-through æ›éšª")

            # è¿½ç¹³äº‹ä»¶
            if results.margin_call_events:
                st.subheader("âš ï¸ è¿½ç¹³äº‹ä»¶")
                events_df = pd.DataFrame(results.margin_call_events)
                events_df['date'] = pd.to_datetime(events_df['date']).dt.strftime('%Y-%m-%d')
                for col in ['im_today', 'mm_today', 'equity', 'required_deposit']:
                    events_df[col] = events_df[col].apply(lambda x: f"{x:,.0f}")
                st.dataframe(events_df, use_container_width=True)

            # ä¸‹è¼‰å€
            st.subheader("ğŸ“¥ ä¸€éµå­˜æª”")

            # HTML å ±å‘Šï¼ˆä¸»è¦ï¼‰
            html_report = create_html_report(results, positions)
            st.download_button(
                label="ğŸŒ ä¸‹è¼‰å®Œæ•´å ±å‘Š (HTML)",
                data=html_report.encode('utf-8'),
                file_name=f"ä¿è­‰é‡‘æ¨¡æ“¬å ±å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html",
                use_container_width=True,
                type="primary"
            )
            st.caption("ğŸ’¡ HTML å ±å‘Šå¯ç›´æ¥ç”¨ç€è¦½å™¨é–‹å•Ÿï¼ŒåŒ…å«æ‰€æœ‰åœ–è¡¨èˆ‡æ•¸æ“šï¼Œæ–¹ä¾¿å‚³çµ¦ä»–äººæª¢è¦–")

            # å…¶ä»–æ ¼å¼
            with st.expander("å…¶ä»–åŒ¯å‡ºæ ¼å¼"):
                col1, col2 = st.columns(2)

                with col1:
                    csv_buffer = io.StringIO()
                    ts.to_csv(csv_buffer, index=False, encoding='utf-8-sig')

                    st.download_button(
                        label="ğŸ“„ ä¸‹è¼‰é€æ—¥æ˜ç´° CSV",
                        data=csv_buffer.getvalue().encode('utf-8-sig'),
                        file_name=f"margin_timeseries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

                with col2:
                    zip_data = create_audit_zip(results, positions)

                    st.download_button(
                        label="ğŸ“¦ ä¸‹è¼‰ç¨½æ ¸åŒ… ZIP",
                        data=zip_data,
                        file_name=f"audit_package_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                        mime="application/zip",
                        use_container_width=True
                    )

            # å‡è¨­èªªæ˜
            with st.expander("ğŸ“ å‡è¨­èˆ‡ä¿å®ˆå£å¾‘èªªæ˜"):
                for assumption in results.assumptions:
                    st.write(f"- {assumption}")

                if results.missing_codes:
                    st.warning(f"âš ï¸ ç™¼ç¾ {len(results.missing_codes)} æª”ç¼ºç¢¼ï¼Œä»¥ä¿å®ˆå£å¾‘è™•ç†")
                    st.write("ç¼ºç¢¼æ¸…å–®ï¼ˆå‰ 20 æª”ï¼‰ï¼š")
                    st.code(", ".join(results.missing_codes[:20]))


if __name__ == "__main__":
    main()
